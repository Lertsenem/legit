#!/usr/bin/python
#*-* encoding:utf8 *-*
########################################
# Project :	LEGIT
#
# Description :	This script imports all law text from a given URL and does the necessary organization.
#		Based on BeautifulSoup 4 python module.
#
# Author :	Lertsenem	<lertsenem@yahoo.fr>
########################################

# IMPORTS
########################################
import sys,os

import urllib2
import argparse

from bs4 import BeautifulSoup


# GLOBAL
########################################
legit_legifrance_sectionsMarkers  = {
	"TM1Code" : 1,
	"TM2Code" : 2,
	"TM3Code" : 3,
	"TM4Code" : 4,
	"TM5Code" : 5,
	"TM6Code" : 6
}

legit_legifrance_rootURL = "http://www.legifrance.gouv.fr"

legit_nametrunksize=50

currentDir = ["org"]

# FUNCTIONS
########################################
# ======================================
def _legit_import_mkdir(dirPathList):
	"""Create a directory using a path given as a list of directories.

	The name of the dircetory is truncated to legit_nametrunksize characters,
	and the complete name is saved in a title file.
	"""
	
	try:
		# Trunk the name if it's more than acceptable
		completeTitle = dirPathList[-1]

		if(len(dirPathList[-1]) > legit_nametrunksize) :
			dirPathList[-1] = dirPathList[-1][:legit_nametrunksize]+"..."

		path = reduce(lambda x,y: x + "/" + y, dirPathList)
		os.mkdir(path)

		# Create a file with the complete title in it.
		ftitle = open(path + "/title", 'w')
		ftitle.write(completeTitle.encode("utf8"))
		ftitle.close()

	# OSError mostly means that the file already exists
	except OSError:
		return

# ======================================
def _legit_import_symlink(name, dirPathList):
	"""Create a symlink for a file of given name in a given subdirectory.

	The subdirectory must be given as a list of directories.
	"""

	# Local variables : dstPath is the destination path for the symlink
	dstPath = (reduce(lambda x,y: x + "/" + y, dirPathList) + "/" + name)
	# Local variables : srcPath is the source path for the symlink (and will be completed later)
	srcPath = ""
	
	# Let's go all the way back up to the file.
	for k in dirPathList:
		srcPath += "../"

	srcPath += name

	# Symlink creation.
	os.symlink(srcPath, dstPath)

# ======================================
def _legit_import_newSection(currentDir, level, name):
	"""Changes the currently analyzed directory based on the level of a span marker.

	The currently analyzed directory must be given as a list.
	The level is a number : 1 is a root element, etc.
	The span is the BeautifulSoup object associated to the marker.
	"""

	# If our current level is below the targetted one, there's something wrong.
	if len(currentDir) < level:
		raise Exception("Fatal : " + str(currentDir))

	# Be sure to go up to the targetted level
	while len(currentDir) > level:
		currentDir.pop()

	# Add the new section to the targeted level
	currentDir.append(name)

	return name


# SCRIPT
########################################
# Arguments Parsing
parser = argparse.ArgumentParser(description='Extract raw code from a legifrance URL')

parser.add_argument("url", metavar="URL", help="A legifrance URL pointing to a Code")
parser.add_argument("--no-organization", dest="organize", action="store_false", help="Do not use the symlink-based organization")

args = parser.parse_args()

# Create organization root directory if needed.
if(args.organize):
	_legit_import_mkdir(currentDir)

# Go fetch that URL
rootHTML = urllib2.urlopen(args.url).read()
rootSoup= BeautifulSoup(rootHTML)
rootSpanList = rootSoup.find_all("span")

for s in rootSpanList :

	if not s.has_attr("class") :
		continue
		
	spanName = s.text.rstrip().lstrip().replace(".", "").replace(" ", "_")

	# CHECKS whether it's a section change
	for mark in legit_legifrance_sectionsMarkers :
		if mark in s["class"] :
			_legit_import_newSection(currentDir, legit_legifrance_sectionsMarkers[mark], spanName)

			if(args.organize):
				_legit_import_mkdir(currentDir)

			break
	
	# CHECKS whether it's an article !
	if "codeLienArt" in s["class"] :
		articleURL = legit_legifrance_rootURL + "/" + s.find("a")["href"]
		articleHTML = urllib2.urlopen(articleURL).read()
		articleSoup = BeautifulSoup(articleHTML)
		articleListe = articleSoup.find_all("div", {"class":"article"})

		for art in articleListe :
			# Get the title
			try:
				titre = (art.find("div", {"class" : "titreArt"})).contents[0].rstrip().lstrip().replace(".", "").replace(' ', '_')
			except Exception as ex:
				print(art)
				print(str(ex.args))
				continue

			# Get the body
			try:
				corps = art.find("div", {"class" : "corpsArt"}).text
				
				# Body treatment
				corps = corps.rstrip().lstrip() + "\n"
				corps = corps.replace("\n\t", "\n")
				corps = corps.replace("\n    ", "\n")
				corps = corps.replace("\n   ", "\n")
				corps = corps.replace("\n  ", "\n")
				corps = corps.replace("\n ", "\n")
			except Exception as ex:
				print("body error - " + titre.encode("utf8") + " : " + str(ex.args))
				continue

			# Write it out !
			try:
				fileName = titre

				fart = open(fileName, 'w')
				fart.write(corps.encode("utf8"))
				fart.close()
			except Exception as ex:
				print("filewrite error - " + titre.encode("utf8") + " : " + str(ex.args))
				continue

			if (args.organize):
				try:
					_legit_import_symlink(fileName, currentDir)
				except Exception as ex:
					print("symlink error - " + titre.encode("utf8") + " : " + str(ex.args))
					continue
